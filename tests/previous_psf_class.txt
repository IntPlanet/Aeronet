
# a very useful tool for recover functions!!!!!!
def rescue_code(function):
    import inspect
    get_ipython().set_next_input("".join(inspect.getsourcelines(function)[0]))



import os
import sys
sys.path.insert(0,'python')
from functools import partial
import gdal
import scipy
from scipy import ndimage, signal, optimize
import tifffile
from mgrspy import mgrs as mg 
from multi_process import parmap
from cloud import classification
from get_brdf import get_brdf_six
from spatial_mapping import mtile_cal,Find_corresponding_pixels, cloud_dilation
from create_training_set import create_training_set

class PSF_optimization(object):
    
    def __init__(self, s2_dir=None, m_fname=None, patch = (0,0,10980, 10980), qa_thresh=2):
        
        self.s2_dir = s2_dir
        self.Lfile = m_fname
        self.patch = patch
        self.bands = 'B02', 'B03', 'B04', 'B08', 'B11', 'B12', 'B8A'
        self.slop = 0.95607605898444503
        self.off =  0.0086119174434039214
        self.qa_thresh = qa_thresh
        
    
    def S2_PSF_optimization(self):

        
        # open the created vrt file with 10 meter, 20 meter and 60 meter 
        # grouped togehter and use gdal memory map to open it
        g = gdal.Open(self.s2_dir+'10meter.vrt')
        data= g.GetVirtualMemArray()
        b2,b3,b4,b8 = data
        g1 = gdal.Open(self.s2_dir+'20meter.vrt')
        data1 = g1.GetVirtualMemArray()
        b8a, b11, b12 = data1[-3:,:,:]
        bands = 'B02', 'B03', 'B04', 'B08', 'B11', 'B12', 'B8A'
        img = dict(zip(self.bands, [b2,b3,b4,b8, b8a, b11, b12]))
        
        if glob(self.s2_dir+'cloud.tiff')==[]:
            cl = classification(img = img)
            cl.Get_cm_p()
            g=None; g1=None
            self.cloud = cl.cm
            g = gdal.Open(self.s2_dir+'B04.jp2')
            driver = gdal.GetDriverByName('GTiff')
            g1 = driver.Create(self.s2_dir+'cloud.tiff', g.RasterXSize, g.RasterYSize, 1, gdal.GDT_Byte)

            projection   = g.GetProjection()
            geotransform = g.GetGeoTransform()
            g1.SetGeoTransform( geotransform )
            g1.SetProjection( projection )
            gcp_count = g.GetGCPs()
            if gcp_count != 0:
                g1.SetGCPs( gcp_count, g.GetGCPProjection() )
            g1.GetRasterBand(1).WriteArray(self.cloud)
            g1=None; g=None
            del cl
        else:
            self.cloud = cloud = gdal.Open(self.s2_dir+'cloud.tiff').ReadAsArray().astype(bool)
        cloud_cover = 1.*self.cloud.sum()/self.cloud.size
        cloud_cover = 1.*self.cloud.sum()/self.cloud.size
        if cloud_cover > 0.2:  
            print 'Too much cloud, cloud proportion: %.03f !!'%cloud_cover
            return []
        else:
        
            mete = readxml('%smetadata.xml'%self.s2_dir)
            self.sza = np.zeros(7)
            self.sza[:] = mete['mSz']
            self.saa = self.sza.copy()
            self.saa[:] = mete['mSa']
            try:
                self.vza = (mete['mVz'])[[1,2,3,7,11,12,8],]
                self.vaa = (mete['mVa'])[[1,2,3,7,11,12,8],]
            except:
                self.vza = np.repeat(np.nanmean(mete['mVz']), 7)
                self.vaa = np.repeat(np.nanmean(mete['mVa']), 7)
            angles = (self.sza[-2], self.vza[-2], (self.vaa - self.saa)[-2])

            tiles = Find_corresponding_pixels(self.s2_dir+'B04.jp2', destination_res=500)
            
            self.h,self.v = int(self.Lfile.split('.')[-4][1:3]), int(self.Lfile.split('.')[-4][4:])
            
            self.H_inds, self.L_inds = tiles['h%02dv%02d'%(self.h, self.v)]
            
            self.Lx, self.Ly = self.L_inds
            self.Hx, self.Hy = self.H_inds
            
            self.brdf, self.qa = get_brdf_six(self.Lfile, angles=angles, bands=(7,), Linds=list(self.L_inds))
            self.brdf, self.qa = self.brdf.flatten(), self.qa.flatten()
            
            # convolve band 12 using the generally used PSF value
            self.H_data = np.repeat(np.repeat(b12, 2, axis=1), 2, axis=0)
            size = 2*int(round(max(1.96*50, 1.96*50)))# set the largest possible PSF size
            self.H_data[0,:]=self.H_data[-1,:]=self.H_data[:,0]=self.H_data[:,-1]=0
            self.bad_pixs = cloud_dilation( (self.H_data <= 0) | self.cloud , iteration=size/2) 
            xstd, ystd = 29.75, 39
            ker = self.gaussian(xstd, ystd, 0)
            self.conved = signal.fftconvolve(self.H_data, ker, mode='same')
            
            in_patch_m = np.logical_and.reduce(((self.Hx>self.patch[1]),
                                                (self.Hx<(self.patch[1]+self.patch[3])), 
                                                (self.Hy>self.patch[0]),
                                                (self.Hy<(self.patch[0]+self.patch[2]))))
            
            self.patch_s2_ind = self.Hx[in_patch_m]-self.patch[1], self.Hy[in_patch_m]-self.patch[0]
            self.patch_mod = self.brdf[in_patch_m]
            self.patch_qa = self.qa[in_patch_m]

            min_val = [-50,-50]
            max_val = [50,50]
            ps, distributions = create_training_set([ 'xs', 'ys'], min_val, max_val, n_train=50)
            solved = parmap(self.shift_optimize, ps, nprocs=10)    
            self.paras, self.costs = np.array([i[0] for i in solved]),np.array([i[1] for i in solved])
            xs, ys = self.paras[self.costs==self.costs.min()][0]
            print 'Best shift is ', xs, ys
            if self.costs.min()<0.1:
                min_val = [12,12, -15,xs-2,ys-2]
                max_val = [50,50, 15, xs+2,ys+2]
                self.bounds = [12,50],[12,50],[-15,15],[xs-2,xs+2],[ys-2, ys+2]

                ps, distributions = create_training_set(['xstd', 'ystd', 'ang', 'xs', 'ys'], min_val, max_val, n_train=50)
                print 'Start solving...'
                self.gaus_solved = parmap(self.gaus_optimize, ps, nprocs=10)
                #print self.solved
                #return self.solved, self.brdf, self.qa 
            else:
                print 'Cost is too large, plese check!', xs, ys, costs.min()
                return []
           
                        
    def shift_cost(self, shifts):
        xs, ys = shifts
        conved_masked = ma.array(self.conved, mask=self.bad_pixs)
        cos = self.cost(xs=xs, ys=ys, conved_masked=conved_masked)      
    
    def gaus_cost(self, paras):
        
        xstd,ystd,angle, xs, ys = para 
        ker = self.gaussian(xstd,ystd,angle,True)                              
        conved = signal.fftconvolve(self.H_data, ker, mode='same')
        # remove the bad pixel
        conved_masked = ma.array(conved, mask=self.bad_pixs)
        cos = self.cost(xs=xs, ys=ys, conved_masked=conved_masked)
    
    def cost(self,xs=None, ys=None, conved_masked=None):
        xs, ys, conved_masked = para
        x_ind, y_ind = (self.patch_s2_ind[0]+xs).astype(int), (self.patch_s2_ind[1]+ys).astype(int)
        mask = np.logical_and.reduce((((x_ind>0),
                                      (x_ind<self.patch[3]),
                                      (y_ind>0),
                                      (y_ind<self.patch[2]),
                                      (self.patch_qa<self.qa_thresh))))

        sb12, mb12 = conved_masked[x_ind[mask], y_ind[mask]], self.patch_mod[mask]
        this_final_mask = mb12.mask|sb12.mask
        m_fed, s_fed = self.slop*mb12[~this_final_mask]+self.off, sb12[~this_final_mask]*0.0001
        try:
            r = scipy.stats.linregress(m_fed, s_fed)
            cost = abs(1-r.rvalue)
        except:
            # no value can be used for regression, i.e. without high quality pixels
            cost = 100000000000
        return cost

    def gaussian(self, xstd, ystd, angle, norm = True):
        win = 2*int(round(max(1.96*xstd, 1.96*ystd)))
        winx = int(round(win*(2**0.5)))
        winy = int(round(win*(2**0.5)))
        xgaus = signal.gaussian(winx, xstd)
        ygaus = signal.gaussian(winy, ystd)
        gaus  = np.outer(xgaus, ygaus)
        r_gaus = ndimage.interpolation.rotate(gaus, angle, reshape=True)
        center = np.array(r_gaus.shape)/2
        cgaus = r_gaus[center[0]-win/2: center[0]+win/2, center[1]-win/2:center[1]+win/2]
        if norm:
            return cgaus/cgaus.sum()
        else:
            return cgaus 

    def _cost2(self, para):
        xstd,ystd,angle, xs, ys = para 
        G = self.gaussian(xstd,ystd,angle,True)                              
        ss = signal.fftconvolve(self.H_data, G, mode='same')
        # remove the cloud pixel
        ss[~self.val_mask]=np.nan
        val = (self.Hx+xs<self.H_data.shape[0])&(self.Hy+ys<self.H_data.shape[1])
        shx, shy = (self.Hx+xs).astype(int), (self.Hy+ys).astype(int)
        Lvals, Hvals = self.L_data[val], ss[shx[val], shy[val]]
        Lvals[np.isnan(Lvals)],Hvals[np.isnan(Hvals)]=-9999999, -9999999
        mas = (Lvals>0)&(Lvals<1)&(Hvals>0)&(Hvals<1)
        try:
            r = scipy.stats.linregress(Lvals[mas], Hvals[mas])
            costs = abs(1-r.rvalue)
        except:
            costs = 100000000000
        return costs 
    
    def shift_optimize(self, p0):
        return optimize.fmin(self.shift_cost, p0, full_output=1, maxiter=100, maxfun=150, disp=0)
    
    def gaus_optimize(self, p0):
        return optimize.fmin_l_bfgs_b(self._cost2, p0, approx_grad=1, iprint=-1, bounds=self.bounds,maxiter=100, maxfun=150)